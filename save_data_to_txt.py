import os
import glob
import pandas as pd
import numpy as np

# --- Import functions from construct_datastore.py ---
# Assuming construct_datastore.py is in the same directory or Python path
try:
    # We only need the read function, not the whole class for this script
    from construct_datastore import read_member_data
except ImportError:
    print("Error: Could not import 'read_member_data' from 'construct_datastore.py'.")
    print("Make sure 'construct_datastore.py' is in the same directory or your PYTHONPATH.")
    exit() # Exit if we can't import the necessary function

# --- Configuration ---
input_folder = 'data_files'       # Folder with the .mat files generated by prepare_data.py
output_folder = 'data_files_txt'  # Folder to save the new .txt files
extension = '.mat'

# Variables to read from each member file and save to text files
# This list determines what data read_member_data will process and return
variables_to_process = [
    # Condition Variables (will be used for metadata, not separate files)
    "Health",
    "Load",
    # Selected Signals/Spectra for saving
    "Ia",
    "Vib_acpi",
    "Vib_acpi_env", # Synthetic envelope signal
    "Ia_env_ps"     # Synthetic envelope spectrum
    # Add other original or synthetic variables here if needed
]

# Variables that represent time-series or frequency-series data to be saved to individual files
data_variables_to_save = [var for var in variables_to_process if var not in ["Health", "Load"]]

# --- Main Script ---

if __name__ == "__main__":

    print("Starting data export to TXT format...")

    # Create the output directory if it doesn't exist
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)
        print(f"Created output directory: {output_folder}")

    # Find all .mat files in the input directory
    mat_files = sorted(glob.glob(os.path.join(input_folder, f'*{extension}')))

    if not mat_files:
        print(f"Error: No '{extension}' files found in '{input_folder}'.")
        print("Please run 'prepare_data.py' first.")
        exit()

    print(f"Found {len(mat_files)} member files to process.")

    processed_count = 0
    error_count = 0

    # Iterate through each .mat file
    for mat_filepath in mat_files:
        base_filename = os.path.splitext(os.path.basename(mat_filepath))[0]
        print(f"\nProcessing: {base_filename}{extension}")

        # Read the data for this member using the imported function
        member_data_series = read_member_data(mat_filepath, variables_to_process)

        if member_data_series is None:
            print(f"  Skipping file {base_filename}{extension} due to read error.")
            error_count += 1
            continue

        # Extract metadata
        health_condition = member_data_series.get('Health', 'Unknown')
        load_condition = member_data_series.get('Load', 'Unknown')

        # Iterate through the data variables we want to save
        for var_name in data_variables_to_save:
            data_to_save = member_data_series.get(var_name)

            if data_to_save is None:
                print(f"  - Variable '{var_name}' is None or missing. Skipping save.")
                continue

            # Construct the output TXT filename
            output_txt_filename = f"{base_filename}_{var_name}.txt"
            output_txt_filepath = os.path.join(output_folder, output_txt_filename)

            print(f"  - Saving '{var_name}' to {output_txt_filename}...")

            try:
                with open(output_txt_filepath, 'w') as f:
                    # Write metadata header
                    f.write(f"# Source File: {os.path.basename(mat_filepath)}\n")
                    f.write(f"# Health Condition: {health_condition}\n")
                    f.write(f"# Load Condition: {load_condition}\n")
                    f.write(f"# Variable: {var_name}\n")
                    f.write("#\n") # Separator line

                # Append data using pandas.to_csv
                if isinstance(data_to_save, pd.Series):
                    # Time-domain signals (index is time)
                    data_to_save.to_csv(output_txt_filepath, mode='a', sep='\t', index=True, header=[var_name], index_label="Time(s)", float_format='%.8f')
                elif isinstance(data_to_save, pd.DataFrame):
                    # Frequency-domain spectra (like Ia_env_ps)
                    data_to_save.to_csv(output_txt_filepath, mode='a', sep='\t', index=False, header=True, float_format='%.8f')
                elif isinstance(data_to_save, np.ndarray):
                     # Handle raw numpy arrays if they somehow appear (unlikely with current read_member_data)
                     # Decide on a default header or save without one
                     df_temp = pd.DataFrame(data_to_save)
                     df_temp.to_csv(output_txt_filepath, mode='a', sep='\t', index=False, header=[f'Column_{i+1}' for i in range(data_to_save.shape[1])] if data_to_save.ndim > 1 else [var_name], float_format='%.8f')
                else:
                     print(f"  - Warning: Data type for '{var_name}' is {type(data_to_save)}, not directly savable as CSV. Skipping.")
                     continue # Skip saving this variable for this file

            except Exception as e:
                print(f"  - Error saving {output_txt_filename}: {e}")
                error_count += 1

        processed_count += 1

    # --- Completion Summary ---
    print("\n-----------------------------------")
    print("Data export to TXT complete.")
    print(f"Successfully processed members: {processed_count}")
    print(f"Errors encountered: {error_count}")
    print(f"Text files saved to: {os.path.abspath(output_folder)}")
    print("-----------------------------------")
